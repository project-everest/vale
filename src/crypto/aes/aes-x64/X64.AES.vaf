include "../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../arch/x64/X64.Vale.InsMem.vaf"
include "../../../arch/x64/X64.Vale.InsVector.vaf"
include "../../../arch/x64/X64.Vale.InsAes.vaf"

module X64.AES

#verbatim{:interface}{:implementation}
open Types_s
open FStar.Seq
open AES_s
open X64.Machine_s
open X64.Vale.State_i
open X64.Vale.Decls_i
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.InsVector
open X64.Vale.InsAes
open X64.Vale.QuickCode_i
open X64.Vale.QuickCodes_i
open Types_i
open AES_helpers_i
open Opaque_i
#endverbatim

#reset-options "--z3rlimit 20"

///////////////////////////
// KEY EXPANSION
///////////////////////////

// Given round key for round, generate round key for round + 1
procedure{:quick} KeyExpansionRound(
    inline round:nat64,
    inline rcon:imm8,
    ghost dst:buffer128,
    ghost key:aes_key(AES_128))
    reads
        rdx;
    modifies
        mem; xmm1; xmm2; xmm3; efl;
    requires/ensures
        validDstAddrs128(mem, rdx, dst, 11);
    requires
        0 <= round < 10;
        rcon == aes_rcon(round);
        xmm1 == expand_key_128(key, round);
    ensures
        xmm1 == buffer128_read(dst, round + 1, mem);
        xmm1 == expand_key_128(key, round + 1);
        modifies_buffer_specific128(dst, old(mem), mem, round + 1, round + 1);
{
    AESNI_keygen_assist(xmm2, xmm1, rcon);
    Pshufd(xmm2, xmm2, 255);
    VPSLLDQ4(xmm3, xmm1);
    Pxor(xmm1,xmm3);
    VPSLLDQ4(xmm3, xmm1);
    Pxor(xmm1,xmm3);
    VPSLLDQ4(xmm3, xmm1);
    Pxor(xmm1,xmm3);
    Pxor(xmm1,xmm2);
    Store128_buffer(rdx, xmm1, 16 * (round + 1), dst, round + 1);

    // assert xmm1 == simd_round_key_128(old(xmm1), rcon);
    lemma_simd_round_key(old(xmm1), rcon);
}

procedure{:quick exportOnly}{:recursive}{:decrease n} KeyExpansionRoundUnrolledRecursive(
    ghost key:aes_key(AES_128),
    ghost dst:buffer128,
    inline n:int)
    reads
        rdx;
    modifies
        mem; xmm1; xmm2; xmm3; efl;
    requires/ensures
        validDstAddrs128(mem, rdx, dst, 11);
    requires
        0 <= n <= 10;
        key == quad32_to_seq(xmm1);
        xmm1 == buffer128_read(dst, 0, mem);
        rdx == buffer_addr(dst);
    ensures
        modifies_buffer128(dst, old(mem), mem);
        xmm1 == buffer128_read(dst, n, mem);
        forall j {buffer128_read(dst, j, mem)} :: 0 <= j <= n ==>
            buffer128_read(dst, j, mem) == expand_key_128(key, j);
{
    inline if (0 < n <= 10) {
        KeyExpansionRoundUnrolledRecursive(key, dst, n - 1);
        KeyExpansionRound(n - 1, aes_rcon(n - 1), dst, key);
    }
}

procedure{:quick} KeyExpansionStdcall(
    inline win:bool,
    ghost input_key_b:buffer128,
    ghost output_key_expansion_b:buffer128)
    reads
        rcx; rsi; rdi;
    modifies
        rdx;
        mem; xmm1; xmm2; xmm3; efl;
    lets
        key_ptr := if win then rcx else rdi;
        key_expansion_ptr := if win then rdx else rsi;
        key := quad32_to_seq(buffer128_read(input_key_b, 0, mem));
    requires/ensures
        buffers_disjoint128(input_key_b, output_key_expansion_b); 
        validSrcAddrs128(mem, key_ptr, input_key_b, 1);
        validDstAddrs128(mem, key_expansion_ptr, output_key_expansion_b, 11);
    ensures
        modifies_buffer128(output_key_expansion_b, old(mem), mem);
        forall j {buffer128_read(output_key_expansion_b, j, mem)} :: 0 <= j <= 10 ==>
            buffer128_read(output_key_expansion_b, j, mem) == index(key_to_round_keys(AES_128, key), j);
{
    inline if (win)
    {
        Load128_buffer(xmm1, rcx, 0, input_key_b, 0);
    }
    else
    {
        Load128_buffer(xmm1, rdi, 0, input_key_b, 0);
        Mov64(rdx, rsi);
    }

    Store128_buffer(rdx, xmm1, 0, output_key_expansion_b, 0);
    KeyExpansionRoundUnrolledRecursive(key, output_key_expansion_b, 10);
    lemma_expand_key_128(key, 11);

    // Clear secrets out of registers
    Pxor(xmm1, xmm1);
    Pxor(xmm2, xmm2);
    Pxor(xmm3, xmm3);
}

///////////////////////////
// ENCRYPTION
///////////////////////////

procedure{:quick} AES128EncryptRound(
    inline n:int,
    ghost init:quad32,
    ghost round_keys:seq(quad32),
    ghost keys_buffer:buffer128
    )
    reads
        r8; mem;
    modifies
        xmm0; xmm2; efl;
    requires
        1 <= n < 10 <= length(round_keys);
        xmm0 == rounds(init, round_keys, n - 1);
        r8 == buffer_addr(keys_buffer);
        validSrcAddrs128(mem, r8, keys_buffer, 11);
        buffer128_read(keys_buffer, n, mem) == index(round_keys, n);
    ensures
        xmm0 == rounds(init, round_keys, n);
{
    commute_sub_bytes_shift_rows(xmm0);
    Load128_buffer(xmm2, r8, 16 * n, keys_buffer, n);
    AESNI_enc(xmm0, xmm2);
}

procedure{:quick} AES128EncryptBlock(
    ghost input:quad32,
    ghost key:aes_key(AES_128),
    ghost round_keys:seq(quad32),
    ghost keys_buffer:buffer128
    )
    reads
        r8; mem;
    modifies
        xmm0; xmm2; efl;
    requires
        length(round_keys) == 11;
        round_keys == key_to_round_keys(AES_128, key);
        xmm0 == input;
        r8 == buffer_addr(keys_buffer);
        validSrcAddrs128(mem, r8, keys_buffer, 11);
        forall i:int :: 0 <= i < 11 ==> buffer128_read(keys_buffer, i, mem) == index(round_keys, i);
    ensures
        xmm0 == aes_encrypt(AES_128, key, input);
{
    assert{:quick_type} length(round_keys) == 11;
    let init := quad32_xor(input, index(round_keys, 0));

    Load128_buffer(xmm2, r8, 0, keys_buffer, 0);
    Pxor(xmm0, xmm2);
    AES128EncryptRound(1, init, round_keys, keys_buffer);
    AES128EncryptRound(2, init, round_keys, keys_buffer);
    AES128EncryptRound(3, init, round_keys, keys_buffer);
    AES128EncryptRound(4, init, round_keys, keys_buffer);
    AES128EncryptRound(5, init, round_keys, keys_buffer);
    AES128EncryptRound(6, init, round_keys, keys_buffer);
    AES128EncryptRound(7, init, round_keys, keys_buffer);
    AES128EncryptRound(8, init, round_keys, keys_buffer);
    AES128EncryptRound(9, init, round_keys, keys_buffer);
    commute_sub_bytes_shift_rows(xmm0);
    Load128_buffer(xmm2, r8, 16 * 10, keys_buffer, 10);
    AESNI_enc_last(xmm0, xmm2);

    // Clear secrets out of registers
    Pxor(xmm2, xmm2);
}

procedure{:quick} AES128EncryptBlockStdcall(
    inline win:bool,
    ghost input:quad32,
    ghost key:aes_key(AES_128),
    ghost input_buffer:buffer128,
    ghost output_buffer:buffer128,
    ghost keys_buffer:buffer128
    )
    reads
        rcx; rdx; rsi; rdi;
    modifies
        r8;
        mem; xmm0; xmm2; efl;
    lets
        output_ptr := if win then rcx else rdi;
        input_ptr := if win then rdx else rsi;
        expanded_key_ptr := if win then r8 else rdx;
    requires
        buffer128_read(input_buffer, 0, mem) == input;
        expanded_key_ptr == buffer_addr(keys_buffer);
        validSrcAddrs128(mem, input_ptr, input_buffer, 1);
        validSrcAddrs128(mem, output_ptr, output_buffer, 1);
        validSrcAddrs128(mem, expanded_key_ptr, keys_buffer, 11);
        forall i:int :: 0 <= i < 11 ==>
            buffer128_read(keys_buffer, i, mem) == index(key_to_round_keys(AES_128, key), i);
    ensures
        modifies_mem(loc_buffer(output_buffer), old(mem), mem);
        validSrcAddrs128(mem, output_ptr, output_buffer, 1);
        buffer128_read(output_buffer, 0, mem) == aes_encrypt(AES_128, key, input);
{
    inline if (win)
    {
        Load128_buffer(xmm0, rdx, 0, input_buffer, 0);
    }
    else
    {
        Load128_buffer(xmm0, rsi, 0, input_buffer, 0);
        Mov64(r8, rdx);
    }

    AES128EncryptBlock(input, key, key_to_round_keys(AES_128, key), keys_buffer);

    inline if (win)
    {
        Store128_buffer(rcx, xmm0, 0, output_buffer, 0);
    }
    else
    {
        Store128_buffer(rdi, xmm0, 0, output_buffer, 0);
    }
}






/*
///////////////////////////
// KEY INVERSION
///////////////////////////

procedure KeyInversionRound(
    inline round:int,
//    inline taint:taint,
    ghost k_b:buffer128)
//    ghost key:aes_key(AES_128),
//    ghost w:seq(nat32),
//    ghost dw_in:seq(nat32)
//    ) returns (
//    ghost dw_out:seq(nat32)
//    )
    requires/ensures
        validSrcAddrs128(mem, rdx, k_b, 11);
    requires
        0 <= round <= 8;
//        SeqLength(w) == 44;
//        SeqLength(dw_in) == 4*(round+1);
//        KeyExpansionPredicate(key, AES_128, w);
//        EqInvkey_expansion_partial(key, AES_128, dw_in, round);
//        forall j :: 0 <= j <= round ==> mem[k_b].quads[rdx + 16*j].v == Quadword(dw_in[4*j], dw_in[4*j+1], dw_in[4*j+2], dw_in[4*j+3]);
//        forall j :: round < j <= 10 ==> mem[k_b].quads[rdx + 16*j].v == Quadword(w[4*j], w[4*j+1], w[4*j+2], w[4*j+3]);
    reads 
        rdx;
    modifies
        mem; xmm1; efl;
    ensures
        modifies_buffer_specific128(k_b, old(mem), mem, round+1, round+1);
//        forall a :: (a < rdx || a >= rdx + 176) && old(mem)[k_b].quads?[a] ==> mem[k_b].quads?[a] && mem[k_b].quads[a] == old(mem)[k_b].quads[a];
//        forall j :: round+1 < j <= 10 ==> mem[k_b].quads[rdx + 16*j].v == Quadword(w[4*j], w[4*j+1], w[4*j+2], w[4*j+3]);
//        SeqLength(dw_out) == 4*(round + 2);
//        forall j :: 0 <= j <= round+1 ==> mem[k_b].quads[rdx + 16*j].v == Quadword(dw_out[4*j], dw_out[4*j+1], dw_out[4*j+2], dw_out[4*j+3]);
//        EqInvkey_expansion_partial(key, AES_128, dw_out, round+1);
{
//    assert mem[k_b].quads[rdx + 16*(round+1)].v == Quadword(w[(round+1)*4], w[(round+1)*4 + 1], w[(round+1)*4 + 2], w[(round+1)*4 + 3]);

    Load128_buffer(xmm1, rdx, 16*(round+1), k_b, round+1);
//    assert xmm1 == Quadword(w[(round+1)*4], w[(round+1)*4 + 1], w[(round+1)*4 + 2], w[(round+1)*4 + 3]);
//    ghost var ws := SeqRange(w, (round+1)*4, (round+1)*4 + 4);
//    assert ws[0] == w[(round+1)*4] && ws[1] == w[(round+1)*4+1] && ws[2] == w[(round+1)*4+2] && ws[3] == w[(round+1)*4+3];
//    assert xmm1 == seq_to_Quadword(ws);
    AESNI_imc(xmm1, xmm1);
    Store128_buffer(rdx, xmm1, 16*(round+1), k_b, round+1);

//    dw_out := dw_in + Quadword_to_seq(xmm1);
//    lemma_KeyInversionRoundHelper(round+1, key, w, dw_in, dw_out);
//
//    forall j :| round+1 < j <= 10 :: mem[k_b].quads[rdx + 16*j].v == Quadword(w[4*j], w[4*j+1], w[4*j+2], w[4*j+3]) {
//    }
//
//    forall j :| 0 <= j <= round + 1 :: mem[k_b].quads[rdx + 16*j].v == Quadword(dw_out[4*j], dw_out[4*j+1], dw_out[4*j+2], dw_out[4*j+3]) {
//    }
}

procedure {:recursive} KeyInversionRoundUnrolledRecursive(
    inline rounds:int,
//    inline taint:taint,
    ghost k_b:buffer128)
//    ghost key:aes_key(AES_128),
//    ghost w:seq(nat32),
//    ghost dw_in:seq(nat32)
//    ) returns (
//    ghost dw_out:seq(nat32)
//    )
    requires/ensures
        validSrcAddrs128(mem, rdx, k_b, 11);
    requires
        0 <= rounds <= 9;
        rdx % 16 == 0;
//        SeqLength(w) == 44;
//        SeqLength(dw_in) == 4;
//        KeyExpansionPredicate(key, AES_128, w);
//        EqInvkey_expansion_partial(key, AES_128, dw_in, 0);
//        mem[k_b].quads[rdx+16*0].v == Quadword(dw_in[4*0], dw_in[4*0+1], dw_in[4*0+2], dw_in[4*0+3]);
//        forall j :: 0 <= j <= 0 ==> mem[k_b].quads[rdx + 16*j].v == Quadword(dw_in[4*j], dw_in[4*j+1], dw_in[4*j+2], dw_in[4*j+3]);
//        forall j :: 0 < j <= 10 ==> mem[k_b].quads[rdx + 16*j].v == Quadword(w[4*j], w[4*j+1], w[4*j+2], w[4*j+3]);
    reads 
        rdx;
    modifies
        mem; xmm1; efl;
    ensures
        modifies_buffer128(k_b, old(mem), mem);
//        forall a :: (a < rdx || a >= rdx + 176) && old(mem)[k_b].quads?[a] ==> mem[k_b].quads?[a] && mem[k_b].quads[a] == old(mem)[k_b].quads[a];
//        SeqLength(dw_out) == 4*(rounds+1);
//        forall j :: 0 <= j <= rounds ==> mem[k_b].quads[rdx + 16*j].v == Quadword(dw_out[4*j], dw_out[4*j+1], dw_out[4*j+2], dw_out[4*j+3]);
//        forall j :: rounds < j <= 10 ==> mem[k_b].quads[rdx + 16*j].v == Quadword(w[4*j], w[4*j+1], w[4*j+2], w[4*j+3]);
//        EqInvkey_expansion_partial(key, AES_128, dw_out, rounds);
{
//    inline if (0 < rounds <= 9) {
//        ghost var dw_mid;
//        dw_mid := KeyInversionRoundUnrolledRecursive(rounds-1, taint, k_b, key, w, dw_in);
//        dw_out := KeyInversionRound(rounds-1, taint, k_b, key, w, dw_mid);
//    }
//    else {
//        dw_out := dw_in;
//    }
}

procedure KeyInversionImpl(
//    ghost key:aes_key(AES_128),
//    ghost w:seq(nat32),
//    inline taint:taint,
    ghost k_b:buffer128)
//    ) returns (
//    ghost dw:seq(nat32)
//    )
    requires/ensures
        validSrcAddrs128(mem, rdx, k_b, 11);
    requires
        rdx % 16 == 0;
//        SeqLength(w) == 44;
//        forall j :: 0 <= j <= 10 ==> mem[k_b].quads[rdx + 16*j].v == Quadword(w[4*j], w[4*j+1], w[4*j+2], w[4*j+3]);
//        KeyExpansionPredicate(key, AES_128, w);
    ensures
        modifies_buffer128(k_b, old(mem), mem);
//        forall a :: (a < rdx || a >= rdx + 176) && old(mem)[k_b].quads?[a] ==> mem[k_b].quads?[a] && mem[k_b].quads[a] == old(mem)[k_b].quads[a];
//        SeqLength(dw) == 44;
//        EqInvKeyExpansionPredicate(key, AES_128, dw);
//        forall j :: 0 <= j <= 10 ==> mem[k_b].quads[rdx + 16*j].v == Quadword(dw[4*j], dw[4*j+1], dw[4*j+2], dw[4*j+3]);
    reads
        rdx;
    modifies
        mem; xmm1; efl;
{
//    lemma_KeyExpansionPredicateImpliesExpandKey(key, AES_128, w);
//    ghost var dw1 := seq(w[0], w[1], w[2], w[3]);
//
//    ghost var dw2;
//    dw2 := KeyInversionRoundUnrolledRecursive(9, taint, k_b, key, w, dw1);
    KeyInversionRoundUnrolledRecursive(9, k_b);
//
//    dw := dw2 + seq(w[40], w[41], w[42], w[43]);
//    assert SeqLength(dw) == 44;
//    forall j :| 0 <= j <= 10 :: mem[k_b].quads[rdx + 16*j].v == Quadword(dw[4*j], dw[4*j+1], dw[4*j+2], dw[4*j+3])
//    {
//    }
//    assert EqInvKeyExpansionPredicate(key, AES_128, dw);
}

procedure KeyExpansionAndInversionStdcall(
//    inline taint:taint,
    inline win:bool,
    ghost input_key_b:buffer128,
    ghost output_key_expansion_b:buffer128)
//    ) returns (
//    ghost dw:seq(nat32)
//    )
    reads
        rcx; rsi; rdi;
    modifies
        rdx;
        mem; xmm1; xmm2; xmm3; efl;
    requires
//        HasStackSlots(stack, 2);
        let key_ptr := if win then rcx else rdi;
        let key_expansion_ptr := if win then rdx else rsi;
        key_ptr % 16 == 0;
        key_expansion_ptr % 16 == 0;
        validSrcAddrs128(mem, key_ptr, input_key_b, 1);
        validDstAddrs128(mem, key_expansion_ptr, output_key_expansion_b, 11);
    ensures
        let key_ptr := if win then rcx else rdi;
        let key_expansion_ptr := if win then rdx else rsi;
//        let key := Quadword_to_seq(old(mem)[input_key_id].quads[key_ptr].v);
//        SeqLength(dw) == 44;
//        ValidSrcAddrs(mem, output_key_expansion_id, key_expansion_ptr, 128, taint, 176);
        validSrcAddrs128(mem, key_expansion_ptr, output_key_expansion_b, 11);
        modifies_buffer128(output_key_expansion_b, old(mem), mem);
//        (forall a :: (a < key_expansion_ptr || a >= key_expansion_ptr + 176) && old(mem)[output_key_expansion_id].quads?[a] ==> mem[output_key_expansion_id].quads?[a] && mem[output_key_expansion_id].quads[a] == old(mem)[output_key_expansion_id].quads[a]);
//        (forall j :: 0 <= j <= 10 ==> mem[output_key_expansion_id].quads[key_expansion_ptr + 16*j].v == Quadword(dw[4*j], dw[4*j+1], dw[4*j+2], dw[4*j+3]));
//        EqInvKeyExpansionPredicate(key, AES_128, dw);
{
    ghost var key_ptr := if win then rcx else rdi;
    ghost var key_expansion_ptr := if win then rdx else rsi;
//    ghost var key := Quadword_to_seq(mem[input_key_id].quads[key_ptr].v);

//    LoadStack(eax, 0);                                     // eax := key_ptr (from stack position 0)
    inline if (win)
    {
        Load128_buffer(xmm1, rcx, 0, input_key_b, 0);
    }
    else
    {
        Load128_buffer(xmm1, rdi, 0, input_key_b, 0);
        Mov64(rdx, rsi);
    }
//    ghost var w;
//    w := KeyExpansionImpl(key, taint, output_key_expansion_id); // expand key from xmm1 to region pointed to by rdx
//    dw := KeyInversionImpl(key, w, taint, output_key_expansion_id);
    ghost var key := quad32_to_seq(xmm1);
    KeyExpansionImpl(key, output_key_expansion_b); // expand key from xmm1 to region pointed to by rdx

//    forall j :| 0 <= j <= 10 :: mem[output_key_expansion_id].quads[key_expansion_ptr + 16*j].v == Quadword(dw[4*j], dw[4*j+1], dw[4*j+2], dw[4*j+3])
//    {
//        assert mem[output_key_expansion_id].quads[rdx + 16*j].v == Quadword(dw[4*j], dw[4*j+1], dw[4*j+2], dw[4*j+3]);
//        assert rdx == key_expansion_ptr;
//    }

    // Clear secrets out of registers
//    Xor32(eax, eax);
    Pxor(xmm1, xmm1);
    Pxor(xmm2, xmm2);
    Pxor(xmm3, xmm3);
}
*/
