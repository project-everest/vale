include "../../../arch/x64/X64.Vale.InsBasic.vaf"
include "../../../arch/x64/X64.Vale.InsMem.vaf"
include "../../../arch/x64/X64.Vale.InsVector.vaf"
include "X64.AES.vaf"
include{:fstar} {:open} "GCTR_s"

module X64.GCTR

#verbatim{:interface}{:implementation}
open Words_s
open Types_s
open Types_i
open FStar.Seq
open AES_s
open X64.AES
open GCTR_s
open GCTR_i
open Words.Two_s
open X64.Machine_s
open X64.Memory_i_s
open X64.Vale.State_i
open X64.Vale.Decls_i
open X64.Vale.InsBasic
open X64.Vale.InsMem
open X64.Vale.InsVector
open X64.Vale.InsAes
open X64.Vale.QuickCode_i
open X64.Vale.QuickCodes_i
#endverbatim

#reset-options "--z3rlimit 40"

///////////////////////////
// GCTR encryption
///////////////////////////

// notypecheck due to:cannot unify type "X64.Vale.Decls_i.va_operand_reg_opr64" and "X64.Vale.Decls_i.va_reg_operand"
// for "r12" of "PinsrdImm"
procedure {:quick}{:notypecheck} init_ctr()
    modifies xmm4; efl; r12;
    ensures 
        xmm4 == Mkfour(1, 0, 0, 0);
{
    Pxor(xmm4, xmm4);
    PinsrdImm(xmm4, 1, 0, r12);

    lemma_quad32_xor();
}

procedure {:quick exportOnly} Inc32(inout dst:xmm, one:xmm)
    requires
        one == Mkfour(1, 0, 0, 0);
    modifies 
        efl;
    ensures 
        dst == inc32(old(dst), 1);
{
    Paddd(dst, one);
}

// GCTR encrypt one block
procedure {:quick} gctr_register(
    ghost key:aes_key_LE(AES_128),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128
    )
    lets io @= xmm1; icb_BE @= xmm7;
    reads r8; icb_BE; mem;
    modifies
        xmm0; xmm1; xmm2; efl; r12;

    requires
        // AES reqs
        length(round_keys) == 11;
        round_keys == key_to_round_keys_LE(AES_128, key);
        r8 == buffer_addr(keys_b, mem);
        validSrcAddrs128(mem, r8, keys_b, 11);
        buffer128_as_seq(mem, keys_b) == round_keys;
    ensures
        create(1, io) == gctr_encrypt_LE(icb_BE, create(1, old(io)), AES_128, key);
{
    Mov128(xmm0, icb_BE);
    InitPshufbMask(xmm2, r12);
    Pshufb(xmm0, xmm2);
    AES128EncryptBlock(reverse_bytes_quad32(icb_BE), key, round_keys, keys_b);

    Pxor(xmm1, xmm0);

    // Call a helpful lemma
    gctr_encrypt_one_block(icb_BE, old(io), AES_128, key);
}

procedure {:quick} gctr_core(
    ghost icb_BE:quad32,
    ghost in_b:buffer128,
    ghost out_b:buffer128,
    ghost key:aes_key_LE(AES_128),
    ghost round_keys:seq(quad32),
    ghost keys_b:buffer128
    )
    lets in_ptr @= rax; out_ptr @= rbx; len @= rcx; icb @= xmm7;

    reads
        r8; in_ptr; out_ptr; len;

    modifies
        rdx; r9; r10; r12; xmm0; xmm1; xmm2; xmm4; icb; mem; efl;

    requires
        // GCTR reqs
        icb == icb_BE;
        buffers_disjoint128(in_b, out_b);
        buffers_disjoint128(keys_b, out_b);
        validSrcAddrs128(mem, in_ptr, in_b, len);
        validDstAddrs128(mem, out_ptr, out_b, len);
        in_ptr  + 16 * len < pow2_64;
        out_ptr + 16 * len < pow2_64;
        buffer_length(in_b) == buffer_length(out_b) /\ buffer_length(out_b) == len /\ 256 * buffer_length(in_b) < pow2_32;

        // AES reqs
        length(round_keys) == 11;
        round_keys == key_to_round_keys_LE(AES_128, key);
        r8 == buffer_addr(keys_b, mem);
        validSrcAddrs128(mem, r8, keys_b, 11);
        buffer128_as_seq(mem, keys_b) == round_keys;
    ensures
        modifies_buffer128(out_b, old(mem), mem);
        validSrcAddrs128(mem, out_ptr, out_b, len);
        buffer128_as_seq(mem, out_b) == gctr_encrypt_LE(icb_BE, buffer128_as_seq(old(mem), in_b), AES_128, key);
        icb == icb_BE.(lo0 := icb.lo0);
{
    Mov64(rdx, 0);
    Mov64(r9, in_ptr);
    Mov64(r10, out_ptr);

    init_ctr();
    InitPshufbMask(xmm1, r12);

    while (rdx != len)
        invariant
            //////////////////// Basic indexing //////////////////////
            0 <= rdx <= len;
            r9 == in_ptr + 16 * rdx;
            r10 == out_ptr + 16 * rdx;
            icb == inc32(icb_BE, rdx);

            //////////////////// From requires //////////////////////
            // GCTR reqs
            buffers_disjoint128(in_b, out_b);
            buffers_disjoint128(keys_b, out_b);
            validSrcAddrs128(mem, in_ptr, in_b, len);
            validDstAddrs128(mem, out_ptr, out_b, len);
            in_ptr  + 16 * len < pow2_64;
            out_ptr + 16 * len < pow2_64;

            // AES reqs
            length(round_keys) == 11;
            round_keys == key_to_round_keys_LE(AES_128, key);
            r8 == buffer_addr(keys_b, mem);
            validSrcAddrs128(mem, r8, keys_b, 11);
            buffer128_as_seq(mem, keys_b) == round_keys;

            //////////////////// GCTR invariants //////////////////////
            xmm1 == Mkfour(0x0C0D0E0F, 0x08090A0B, 0x04050607, 0x00010203);
            xmm4 == Mkfour(1, 0, 0, 0);

            //////////////////// Postcondition goals //////////////////////
            modifies_buffer128(out_b, old(mem), mem);
            validSrcAddrs128(mem, out_ptr, out_b, len);
            gctr_partial(rdx, buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, icb_BE);
//            forall j :: 0 <= j < rdx ==>
//                        buffer128_read(out_b, j, mem) ==
//                        quad32_xor(index_workaround(buffer128_as_seq(mem, in_b), j), aes_encrypt_LE(AES_128, key, inc32(icb_BE, j)));

        decreases
            len - rdx;
    {
        Mov128(xmm0, icb);
        Pshufb(xmm0, xmm1);
        AES128EncryptBlock(reverse_bytes_quad32(icb), key, round_keys, keys_b);

        Load128_buffer(xmm2, r9, 0, in_b, rdx);
        Pxor(xmm2, xmm0);
        Store128_buffer(r10, xmm2, 0, out_b, rdx);

        Add64(rdx, 1);
        Add64(r9, 16);
        Add64(r10, 16);
        Inc32(icb, xmm4);
    }

    // Call a helpful lemma
    gctr_partial_completed(buffer128_as_seq(mem, in_b), buffer128_as_seq(mem, out_b), key, icb_BE);
}
